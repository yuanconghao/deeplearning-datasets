天风证券：人工智能之火点燃算力需求 AI服务器迎投资机遇
2023年05月04日 07:41

天风证券研报指出，ChatGPT带来算力的需求快速增长，异构计算成为发展趋势，GPU服务器更适用于处理大算力需求场景，我们判断应用将增加。我们认为ChatGPT的训练和推理场景都将带来服务器市场增量需求，预计未来AI服务器产业链市场规模将迎来快速增长期。
全文如下
天风·通信|人工智能之火点燃算力需求，AI服务器迎投资机遇
核心观点
ChatGPT带来算力的需求快速增长，异构计算成为发展趋势，GPU服务器更适用于处理大算力需求场景，我们判断应用将增加。我们认为ChatGPT的训练和推理场景都将带来服务器市场增量需求，预计未来AI服务器产业链市场规模将迎来快速增长期。
正文
1.服务器构成及市场情况
服务器市场规模持续增长。根据Counterpoint的全球服务器销售跟踪报告，2022年，全球服务器出货量将同比增长6%，达到1380万台。收入将同比增长17%，达到1117亿美元。根据IDC、中商产业研究院，我国服务器市场规模由2019年的182亿美元增长至2022年的273.4亿美元，复合年均增长率达14.5%，预计2023年我国服务器市场规模将增至308亿美元。
竞争格局：根据IDC发布的《2022年第四季度中国服务器市场跟踪报告Prelim》，浪潮份额国内领先，新华三次之，超聚变排行第三，中兴通讯进入前五。
2.AIGC带来服务器变革
AIGC火热，产业生态形成
2022年12月，OpenAI的大型语言生成模型ChatGPT火热，它能胜任刷高情商对话、生成代码、构思剧本和小说等多个场景，将人机对话推向新的高度。全球各大科技企业都在积极拥抱AIGC，不断推出相关技术、平台和应用。
生成算法、预训练模式、多模态等AI技术累计融合，催生了AIGC的大爆发。
目前，AIGC产业生态体系的雏形已现，呈现为上中下三层架构：①第一层为上游基础层，也就是由预训练模型为基础搭建的AIGC技术基础设施层。②第二层为中间层，即垂直化、场景化、个性化的模型和应用工具。③第三层为应用层，即面向C端用户的文字、图片、音视频等内容生成服务。
模型参数量持续提升
GPT模型对比BERT模型、T5模型的参数量有明显提升。GPT-3是目前最大的知名语言模型之一，包含了1750亿（175B）个参数。在GPT-3发布之前，最大的语言模型是微软的TuringNLG模型，大小为170亿（17B）个参数。GPT-3的paper也很长，ELMO有15页，BERT有16页，GPT-2有24页，T5有53页，而GPT-3有72页。
训练数据量不断加大，对于算力资源需求提升。
回顾GPT的发展，GPT家族与BERT模型都是知名的NLP模型，都基于Transformer技术。GPT，是一种生成式的预训练模型，由OpenAI团队最早发布于2018年，GPT-1只有12个Transformer层，而到了GPT-3，则增加到96层。其中，GPT-1使用无监督预训练与有监督微调相结合的方式，GPT-2与GPT-3则都是纯无监督预训练的方式，GPT-3相比GPT-2的进化主要是数据量、参数量的数量级提升。
3.训练&推理带来服务器增量需求
由于OpenAI暂未公开ChatGPT（基于大语言模型GPT-3.5）相关技术细节。估算基于GPT-3。
根据天翼智库，训练阶段的算力估算。
根据OpenAI在2020年发表的论文，训练阶段算力需求与模型参数数量、训练数据集规模等有关，且为两者乘积的6倍：训练阶段算力需求=6×模型参数数量×训练集规模。
GPT-3模型参数约1750亿个，预训练数据量为45TB，折合成训练集约为3000亿tokens。即训练阶段算力需求=6×1.75×1011×3×1011=3.15×1023FLOPS=3.15×108PFLOPS
依据谷歌论文，OpenAI公司训练GPT-3采用英伟达V100GPU，有效算力比率为21.3%。GPT-3的实际算力需求应为1.48×109PFLOPS(17117PFLOPS-day)。
假设应用A100640GB服务器进行训练，该服务器AI算力性能为5PFLOPS，最大功率为6.5kw，则我们测算训练阶段需要服务器数量=训练阶段算力需求÷服务器AI算力性能=2.96×108台（同时工作1秒），即3423台服务器工作1日。
4.AI服务器市场有望迎来高速发展机遇
AI服务器作为算力基础设备有望受益于算力需求持续增长
AI服务器作为算力基础设备，其需求有望受益于AI时代下对于算力不断提升的需求而快速增长。
根据TrendForce，截至2022年为止，预估搭载GPGPU（GeneralPurposeGPU）的AI服务器年出货量占整体服务器比重近1%，预估在ChatBot相关应用加持下，有望再度推动AI相关领域的发展，预估出货量年成长可达8%；2022~2026年复合成长率将达10.8%。
AI服务器是异构服务器，可以根据应用范围采用不同的组合方式，如CPU+GPU、CPU+TPU、CPU+其他加速卡等。IDC预计，中国AI服务器2021年的市场规模为57亿美元，同比增长61.6%，到2025年市场规模将增长到109亿美元，CAGR为17.5%。
5.AI服务器产业链解析
AI服务器核心组件包括GPU（图形处理器）、DRAM（动态随机存取存储器）、SSD（固态硬盘）和RAID卡、CPU（中央处理器）、网卡、PCB、高速互联芯片（板内）和散热模组等。
CPU主要供货厂商为Intel、GPU目前领先厂商为国际巨头英伟达，以及国内厂商如寒武纪、海光信息等。
内存主要为三星、美光、海力士等厂商，国内包括兆易创新等。
SSD厂商包括三星、美光、海力士等，以及国内江波龙等厂商。
PCB厂商海外主要包括金像电子，国内包括沪电股份、鹏鼎控股等。
主板厂商包括工业富联，服务器品牌厂商包括浪潮信息、紫光股份、中科曙光、中兴通讯等。
6.AI服务器竞争格局
IDC发布了《2022年第四季度中国服务器市场跟踪报告Prelim》。从报告可以看到，前两名浪潮与新华三的变化较小，第三名为超聚变，从3.2%份额一跃而至10.1%，增幅远超其他服务器厂商。Top8服务器厂商中，浪潮、戴尔、联想均出现显著下滑，超聚变和中兴则取得明显增长。其中，浪潮份额从30.8%下降至28.1%；新华三份额从17.5%下降至17.2%；中兴通讯（000063）从3.1%提升至5.3%，位居国内第5。联想降幅最为明显，从7.5%下降至4.9%。
据TrendForce集邦咨询统计，2022年AI服务器采购占比以北美四大云端业者Google、AWS、Meta、Microsoft合计占66.2%为最，而中国近年来随着国产化力道加剧，AI建设浪潮随之增温，以ByteDance的采购力道最为显著，年采购占比达6.2%，其次紧接在后的则是Tencent、Alibaba与Baidu，分别约为2.3%、1.5%与1.5%。
国内AI服务器竞争厂商包括：浪潮信息、新华三、超聚变、中兴通讯等。
服务器主要厂商包括：工业富联、浪潮信息、超聚变、紫光股份（新华三）、中兴通讯、中科曙光。
AI服务器目前领先厂商为工业富联和浪潮信息，浪潮信息在阿里、腾讯、百度AI服务器占比高达90%。
紫光股份在GPU服务器市场处于领先地位，有各种类型的GPU服务器满足各种AI场景应用。特别针对GPT场景而优化的GPU服务器已经完成开发，并取得31个世界领先的测试指标，该新一代系列GPU服务器将在今年二季度全面上市。
中兴通讯近年服务器发展较快，年初推出AI服务器G5服务器，此外在布局新一代AI加速芯片、模型轻量化技术，大幅降低大模型推理成本。
风险提示：ChatGPT发展低于预期的风险、ChatGPT政策监管的风险、下游应用推广不及预期、行业竞争加剧，价格和盈利能力下降的风险。

(责任编辑：15)
