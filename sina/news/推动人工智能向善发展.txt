推动人工智能向善发展
2023年04月08日 02:00
来源：中国经营网
朱昌俊
炙手可热的人工智能语言模型ChatGPT正在遭遇一盆盆冷水。继全球千余名科技界人士呼吁暂停训练包括ChatGPT在内的强大人工智能系统之后，联合国教科文组织日前也号召各国立即执行其《人工智能伦理问题建议书》。这份建议书由教科文组织193个会员国一致通过，是首个关于以符合伦理要求的方式运用人工智能的全球框架，旨在指导各国最大限度发挥人工智能优势，降低其带来的风险。
不仅如此，一些国家和企业也对ChatGPT发出禁令。在意大利，数据监管机构宣布禁止ChatGPT在意大利运营；在德国，联邦数据保护专员发言人称，出于数据保护方面的考虑，可能会暂时禁止在德国使用ChatGPT；在韩国，三星表示，为了避免数据泄露事件再次发生，已经告知员工谨慎使用ChatGPT……几乎一夜之间，ChatGPT热潮在全球范围内出现风向逆转。
实际上，ChatGPT自公开亮相的那一刻起，就伴随着巨大的争议。乐观者认为它打开了通向“新世界”的大门，其作为新技术的范式革命将给人类带来全新的机遇；但同时，也有一部分人认为，它可能会全面挑战人类的现有秩序，并带来数据安全、隐私保护等风险。而更多普通人的一个现实担忧是，自己的岗位是不是将被人工智能所替代……
几乎每一轮新的科技革命到来，或是某个重大技术取得新突破时，都会引发社会争议，这在历史上已被重复了很多次。从一定程度上说，它和人类与生俱来的对于未知的恐惧是息息相关的。比如，最近的一个案例是，2019年5月，美国旧金山城市监督委员会通过一条禁令，决定禁止该市所有单位使用人脸识别技术。但这并未带来更多地方的跟进。相反，仅仅差不多半年后，旧金山就对该禁令作出修改，放宽人脸识别的使用限制。
因此，以史为鉴，完全不必过于放大ChatGPT目前所遭遇的“寒流”。事实上，这次全球千余名科技人士的呼吁，也只是要求暂停训练更强大的人工智能系统。联合国教科文组织发出的号召，亦只是强调各国“发展符合伦理规范的人工智能”，并不等于不发展。换言之，这类对ChatGPT“急刹车”的行动，主要还是提醒人类，对于ChatGPT的应用要做好更充分的准备，尽可能趋利避害。与其说这是包括ChatGPT在内的人工智能所遭遇的信任危机，不如说是其成长路上的必经烦恼。
关于ChatGPT的下一步走向，能够在全球范围引起如此大的关注和讨论，其实恰恰说明，其所展现出的技术突破性已经不得不让人正视。而一项创新技术突破性越强，对于现实社会的“改造”越大，就越需要对其伦理规范有更多的审视。近年来，随着人工智能、自动驾驶等新技术不断取得进展，其对应的科技伦理风险和科技治理挑战，也愈发引起重视。比如，中国在2020年就专门成立了国家科技伦理委员会，目的就是加强统筹规范和指导协调，推动构建覆盖全面、导向明确、规范有序、协调一致的科技伦理治理体系。
不过，这次针对ChatGPT的科技伦理规范讨论，尽管在全球取得了一定共识，但不同国家和地区在人工智能技术的研发和应用进度上存在差异，且存在一定的竞争关系，不同社会对新技术的接受程度也不尽一致，因此在谈论科技伦理上，也势必要尊重不同区域的实际情况。历史已证明，对于某项具备趋势性的新技术“一刀切式”的严控或是放纵，只会令技术发展遭遇“科林格里奇困境”。因此，最好的方式只能是在发展中平衡，在平衡中发展。比如，ChatGPT训练时需要遵循哪些伦理，开放应用又要符合哪些前提条件，既避免它带来诸如放大虚假信息、侵犯隐私和知识产权等风险，也考虑它可能给社会就业带来的冲击，这需要尽快明确一些全球性的底线共识，也有必要参照各个国家和地区的现实情况。
当然，守住人工智能发展的伦理大门，一些工作对不同国家来说是共同的挑战，就像这次全球千余科技人士的公开信中所呼吁的。如人工智能开发人员应与政策制定者合作，以加快开发强大的人工智能治理系统。也即，在人工智能技术不断进化的同时，相应的监管机构，或者说对科技伦理的规范力量，也应与时俱进。此外，诸如建立专门负责人工智能的新监管机构；建立水印系统，以帮助人们区分真实与人工智能合成内容；界定人工智能造成的伤害的责任等，同样也是每个国家和地区有必要做好的准备。
“科技向善”的重要性，可能从来没有如此清晰地被所有人所感知。诚如比尔·盖茨所言，真正在全球范围内暂停人工智能技术的开发，已经不太现实。但确保其被健康地使用，防止打开潘多拉魔盒，却是必要的。可以说，各国争相谋求技术突破的同时，如何构建一套适配技术发展和应用的科技伦理治理体系，同样是一条不可忽视的竞争赛道。
责任编辑：李桐
